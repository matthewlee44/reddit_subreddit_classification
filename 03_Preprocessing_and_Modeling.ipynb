{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc4ec6c-e85f-4729-a5af-d959e06db448",
   "metadata": {},
   "source": [
    "# Reddit Subreddit Classification\n",
    "## Notebook 3 - Preprocessing and Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866093c-0c02-47e2-bd04-caf2471795bd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754243d-92fb-40f5-bcb6-cf9753741091",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab0b8b23-ef36-412d-b174-7633d0e8e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from datetime import datetime\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef4e3a-43cd-47ac-a227-087e088d21b4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba33d5cd-b37c-422b-8135-6e0e3fc0d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"./data/final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af7acd-651f-41f3-8f32-4c22158769fe",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Based on my EDA, I thought that it was worth trying two different attempts at changing the text data prior to modeling.\n",
    "1. Consolidating words covering certain topics into one word\n",
    "2. Trying additional stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82530d99-8719-45e6-89c5-854c21bb7ac3",
   "metadata": {},
   "source": [
    "### Consolidating Topic Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd80be-0530-4c36-a12d-807da52ff041",
   "metadata": {},
   "source": [
    "To implement the replacement of all words covering certain topics, I created a function that would run regexs composed to capture tokens covering those topics and replacing them with a single word for that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b2771ce-58b2-41fc-a999-56dd54d66fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all tokens covering a topic into one word\n",
    "def consolidate_topics(X):\n",
    "    print(\"Running consolidate topics\")\n",
    "    # Regexs for topic words\n",
    "    girl = r\"girl[A-Za-z]*(?![0-9])\"\n",
    "    boy_guy = r\"boy|guy\"\n",
    "    marriage = r\"marr[A-Za-z]*\"\n",
    "    divorce = r\"divo[A-Za-z]*\"\n",
    "    over_forty = r\"\\A[4-7][0-9]\\Z|\\A[4-7][0-9](?!pm|min)[^0-9k]\"\n",
    "    under_forty = r\"\\A[2-3][0-9]\\Z|\\A[2-3][0-9](?!pm|min)[^0-9k]\"\n",
    "    kids = r\"\\Akid[s]?\\Z|kiddo|child|\\Ason[s]?\\Z|daughter|grandkid|grandchild|grandson\"\n",
    "    school = r\"\\Aschool|college|universi\"\n",
    "\n",
    "    # Tokenize per sklearn's regex sequence\n",
    "    X = X.str.findall(r\"(?u)\\b\\w\\w+\\b\").apply(lambda x: \" \".join(x))\n",
    "\n",
    "    # Replace all different variations of topic with one word\n",
    "    X = X.str.replace(girl, \"girl\", regex=True)\n",
    "    X = X.str.replace(boy_guy, \"boy\", regex=True)\n",
    "    X = X.str.replace(marriage, \"marriage\", regex=True)\n",
    "    X = X.str.replace(divorce, \"divorce\", regex=True)\n",
    "    X = X.str.replace(over_forty, \"over_forty\", regex=True)\n",
    "    X = X.str.replace(under_forty, \"under_forty\", regex=True)\n",
    "    X = X.str.replace(kids, \"child\", regex=True)\n",
    "    X = X.str.replace(school, \"school\", regex=True)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5dc6c0b4-82fb-4a81-8680-722801080a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FunctionTransformer with the consolidate_topics function\n",
    "consolidate_tf = FunctionTransformer(consolidate_topics, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154590b-1a88-41ac-af27-3d158189b33f",
   "metadata": {},
   "source": [
    "### Additional Stop Words\n",
    "The stop words below were found during EDA and will be tried out during model gridsearches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f374c437-f69f-4a86-b073-b82af8e96385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common words found during EDA that may work as stop words\n",
    "add_stop_words = [\"just\", \"like\", \"date\", \"dating\", \"ve\", \"want\", \n",
    "                  \"time\", \"relationship\", \"think\", \"feel\", \"people\", \n",
    "                  \"don\", \"really\", \"know\", \"said\", \"didn\", \"things\",\n",
    "                 \"going\", \"good\", \"person\"]\n",
    "\n",
    "# Adding additional stop words to default stop words in sklearn's text vectorizer\n",
    "new_stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf444c7-bc07-47c8-8e4f-fcc8b489fd81",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39309c8e-76ea-4f35-8c80-c4f594a71fea",
   "metadata": {},
   "source": [
    "### Declare X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9caf0e32-3e82-4c37-874c-7ff3a30faad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[\"alltext\"]\n",
    "y = final_df[\"||__target__||\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa7531-8e21-47bb-9e8f-6e53ca24ecf6",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5da74bad-4f69-41d9-94f0-4d86a7390528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27b5c9-ad60-438b-9c4a-206d4c623995",
   "metadata": {},
   "source": [
    "### GridSearch Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c671b0e2-04ab-4df2-aff4-75f6b3bf32ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearch(X_train, X_test, y_train, y_test, parameters):\n",
    "    pipeline_items = []\n",
    "    if parameters[\"consolidate_text\"]:\n",
    "        pipeline_items.append((\"consolidate\", consolidate_tf))\n",
    "    pipeline_items.append((\"vec\", parameters['vec']))\n",
    "    pipeline_items.append((\"estimator\", parameters['estimator']))\n",
    "    \n",
    "    pipe = Pipeline(pipeline_items)\n",
    "    \n",
    "    gridsearch_params = parameters['params']\n",
    "    \n",
    "    # Instantiate GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid=gridsearch_params, n_jobs=-1, verbose = 4)\n",
    "\n",
    "    # Fit GridSearch\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Output results\n",
    "    pd.DataFrame(gs.cv_results_).to_csv(f\"./gridsearch_results/{parameters['name']}-{datetime.now()}.csv\", index=False)\n",
    "    \n",
    "    # Print scores\n",
    "    print(f\"Train Score: {gs.score(X_train, y_train)}\")\n",
    "    print(f\"Test Score: {gs.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f03c30-45c0-4d70-aba9-b935d60016b9",
   "metadata": {},
   "source": [
    "### Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bac2d93-ae44-4d62-b86e-9f9863a632ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_con_tf_params = {\n",
    "    \"name\": \"logistic_regression_consolidate_tfidf\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb857c-1b94-4a2c-a439-8ed3ba6d6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_con_count_params = {\n",
    "    \"name\": \"logistic_regression_consolidate_count\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090b817-4cf5-4eef-9ef4-1c4c054a9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_tf_params = {\n",
    "    \"name\": \"logistic_regression_tfidf\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfa375-e965-4bb7-8bba-f14970da2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_count_params = {\n",
    "    \"name\": \"logistic_regression_count\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"none\", \"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4de45-6509-4790-9fca-a1a9928e828e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344cdc1d-7e3f-42a4-b69d-a0e6d199cb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5dfa30-0e3d-4cf9-bed3-156eec2add05",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c64a627-e8ea-4f21-a667-45921f1529ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_con_tf_params = {\n",
    "    \"name\": \"mnb_consolidate_tfidf\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad56096-9f47-493d-8500-3bb2e08d5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_con_count_params = {\n",
    "    \"name\": \"mnb_consolidate_count\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e494324-7900-4e3d-859d-872fd814da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_tf_params = {\n",
    "    \"name\": \"mnb_tfidf\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304368b-fc43-48ba-91cb-be311463317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_count_params = {\n",
    "    \"name\": \"mnb_count\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da4099-fbe5-463e-a774-d824c4b549ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1389a1e4-2202-45f9-8594-1f64b7bd6dac",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a373b-6486-41df-88a4-6b39a50bf957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365b4ab-9624-401f-bf60-e8187b9e3e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df2641-052f-40eb-803f-ddb21aa1c625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f730d44-0c18-4c1a-a048-4925bfbfff38",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d7711-8e3c-45fc-a25a-8475573d4d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70c1ef8c-ff87-487f-b94c-a281722fde4d",
   "metadata": {},
   "source": [
    "### Support Vector Machine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23334028-95b2-4666-a2b4-dbd9f45c0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipe = Pipeline([\n",
    "    (\"svc_ss\", StandardScaler()),\n",
    "    (\"svc\", SVC()),\n",
    "])\n",
    "\n",
    "svc_params = {\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334461c5-5c76-4911-9fbe-b8d6b6e11f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70c80c-3522-4ae5-ab0e-a5253f6a157f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f82af0-96f3-4490-a14e-b0c2e40390f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
