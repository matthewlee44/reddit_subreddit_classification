{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc4ec6c-e85f-4729-a5af-d959e06db448",
   "metadata": {},
   "source": [
    "# Reddit Subreddit Classification\n",
    "## Notebook 3 - Preprocessing and Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866093c-0c02-47e2-bd04-caf2471795bd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754243d-92fb-40f5-bcb6-cf9753741091",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0b8b23-ef36-412d-b174-7633d0e8e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from datetime import datetime\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef4e3a-43cd-47ac-a227-087e088d21b4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba33d5cd-b37c-422b-8135-6e0e3fc0d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"../data/final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af7acd-651f-41f3-8f32-4c22158769fe",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Based on my EDA, I thought that it was worth trying two different attempts at changing the text data prior to modeling.\n",
    "1. Consolidating words covering certain topics into one word\n",
    "2. Trying additional stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82530d99-8719-45e6-89c5-854c21bb7ac3",
   "metadata": {},
   "source": [
    "### Consolidating Topic Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd80be-0530-4c36-a12d-807da52ff041",
   "metadata": {},
   "source": [
    "To implement the replacement of all words covering certain topics, I created a function that would run regexs composed to capture tokens covering those topics and replacing them with a single word for that topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2771ce-58b2-41fc-a999-56dd54d66fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all tokens covering a topic into one word\n",
    "def consolidate_topics(X):\n",
    "#    print(\"Running consolidate topics\")\n",
    "    # Regexs for topic words\n",
    "    girl = r\"girl[A-Za-z]*(?![0-9])\"\n",
    "    boy_guy = r\"boy|guy\"\n",
    "    marriage = r\"marr[A-Za-z]*\"\n",
    "    divorce = r\"divo[A-Za-z]*\"\n",
    "    over_forty = r\"\\A[4-7][0-9]\\Z|\\A[4-7][0-9](?!pm|min)[^0-9k]\"\n",
    "    under_forty = r\"\\A[2-3][0-9]\\Z|\\A[2-3][0-9](?!pm|min)[^0-9k]\"\n",
    "    kids = r\"\\Akid[s]?\\Z|kiddo|child|\\Ason[s]?\\Z|daughter|grandkid|grandchild|grandson\"\n",
    "    school = r\"\\Aschool|college|universi\"\n",
    "\n",
    "    # Tokenize per sklearn's regex sequence\n",
    "    X = X.str.findall(r\"(?u)\\b\\w\\w+\\b\").apply(lambda x: \" \".join(x))\n",
    "\n",
    "    # Replace all different variations of topic with one word\n",
    "    X = X.str.replace(girl, \"girl\", regex=True)\n",
    "    X = X.str.replace(boy_guy, \"boy\", regex=True)\n",
    "    X = X.str.replace(marriage, \"marriage\", regex=True)\n",
    "    X = X.str.replace(divorce, \"divorce\", regex=True)\n",
    "    X = X.str.replace(over_forty, \"over_forty\", regex=True)\n",
    "    X = X.str.replace(under_forty, \"under_forty\", regex=True)\n",
    "    X = X.str.replace(kids, \"child\", regex=True)\n",
    "    X = X.str.replace(school, \"school\", regex=True)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc6c0b4-82fb-4a81-8680-722801080a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FunctionTransformer with the consolidate_topics function\n",
    "consolidate_tf = FunctionTransformer(consolidate_topics, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154590b-1a88-41ac-af27-3d158189b33f",
   "metadata": {},
   "source": [
    "### Additional Stop Words\n",
    "The stop words below were found during EDA and will be tried out during model gridsearches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f374c437-f69f-4a86-b073-b82af8e96385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common words found during EDA that may work as stop words\n",
    "add_stop_words = [\"just\", \"like\", \"date\", \"dating\", \"ve\", \"want\", \n",
    "                  \"time\", \"relationship\", \"think\", \"feel\", \"people\", \n",
    "                  \"don\", \"really\", \"know\", \"said\", \"didn\", \"things\",\n",
    "                 \"going\", \"good\", \"person\"]\n",
    "\n",
    "# Adding additional stop words to default stop words in sklearn's text vectorizer\n",
    "new_stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf444c7-bc07-47c8-8e4f-fcc8b489fd81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling\n",
    "I performed all model fitting using cloud computing instead of on my local computer to speed up the process. The following code was exported to a python file and ran using a python console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e6986b-5e2e-40e9-8f7a-4b7e7461719c",
   "metadata": {},
   "source": [
    "### GridSearch Function\n",
    "The following function was used to run grid searches for each model. The function takes in a dictionary of parameters that specifies all the parameters and the model to use for a gridsearch. It then outputs the cv_results_ and the best scores from the gridsearch to the './gridsearch_results' folder as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a64af5-ca02-495c-aa94-8688186c2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gridsearch(X_train, X_test, y_train, y_test, parameters):\n",
    "    # Create empty list to collect pipeline items\n",
    "    pipeline_items = []\n",
    "    \n",
    "    # If parameters says to consolidate topic words, add topic word replacement function into pipeline\n",
    "    if parameters[\"consolidate_text\"]:\n",
    "        pipeline_items.append((\"consolidate\", consolidate_tf))\n",
    "    \n",
    "    # If parameters specifies a vectorizer, add the vectorizer\n",
    "    if parameters['vec']:\n",
    "        pipeline_items.append((\"vec\", parameters['vec']))\n",
    "    \n",
    "    # If parameters says to add StandardScaler, add it\n",
    "    if parameters['ss']:\n",
    "        pipeline_items.append((\"ss\", StandardScaler()))\n",
    "    \n",
    "    # Add estimator specified in parameters\n",
    "    pipeline_items.append((\"estimator\", parameters['estimator']))\n",
    "\n",
    "    # Instantiate pipeline for gridsearch\n",
    "    pipe = Pipeline(pipeline_items)\n",
    "    \n",
    "    # Add hyper-parameters to grid search over from parameters\n",
    "    gridsearch_params = parameters['params']\n",
    "    \n",
    "    # Instantiate GridSearchCV\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid=gridsearch_params, n_jobs=-1, verbose = 4)\n",
    "\n",
    "    # Fit GridSearch\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Write cv_results_ and best scores from grid search to csv\n",
    "    pd.DataFrame(gs.cv_results_).to_csv(f\"./gridsearch_results/{parameters['name']}-{datetime.now()}.csv\", index=False)\n",
    "    pd.DataFrame({\"train\": gs.score(X_train, y_train), \"test\": gs.score(X_test,y_test)}, index=[\"best_scores\"]).to_csv(f\"./gridsearch_results/best_scores_{parameters['name']}-{datetime.now()}.csv\", index=False)\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39309c8e-76ea-4f35-8c80-c4f594a71fea",
   "metadata": {},
   "source": [
    "### X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caf0e32-3e82-4c37-874c-7ff3a30faad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df[\"alltext\"]\n",
    "y = final_df[\"||__target__||\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa7531-8e21-47bb-9e8f-6e53ca24ecf6",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da74bad-4f69-41d9-94f0-4d86a7390528",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead9c6d-97ce-4eb6-8e7b-e715e12ae209",
   "metadata": {},
   "source": [
    "### Model Parameters\n",
    "The following dictionaries set forth the parameters for each of the models I ran using the run_gridsearch function above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f03c30-45c0-4d70-aba9-b935d60016b9",
   "metadata": {},
   "source": [
    "#### Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bac2d93-ae44-4d62-b86e-9f9863a632ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model with consolidate text function, and TfidfVectorizer\n",
    "log_reg_con_tf_params = {\n",
    "    \"name\": \"logistic_regression_consolidate_tfidf\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"ss\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, new_stop_words],\n",
    "        \"vec__min_df\": [2],\n",
    "        \"vec__max_features\": [None, 5000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "        \"estimator__C\": [0.1,1,10],\n",
    "        \"estimator__max_iter\": [10000]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Logistic regression model with consolidate text function and CountVectorizer\n",
    "log_reg_con_count_params = {\n",
    "    \"name\": \"logistic_regression_consolidate_count\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"ss\": False,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [2, 10],\n",
    "        \"vec__max_features\": [None, 5000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10],\n",
    "        \"estimator__max_iter\": [10000]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Logistic regression model without consolidate_text function and with TfidfVectorizer\n",
    "log_reg_tf_params = {\n",
    "    \"name\": \"logistic_regression_tfidf\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"ss\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, new_stop_words],\n",
    "        \"vec__min_df\": [2, 10],\n",
    "        \"vec__max_features\": [None, 5000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10],\n",
    "        \"estimator__max_iter\": [10000]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Logistic regression model without consolidate_text function and with CountVectorizer\n",
    "log_reg_count_params = {\n",
    "    \"name\": \"logistic_regression_count\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"ss\": False,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": LogisticRegression(solver=\"liblinear\"),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, new_stop_words],\n",
    "        \"vec__min_df\": [2, 10],\n",
    "        \"vec__max_features\": [None, 5000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "        \"estimator__C\": [0.01,0.1,1,10],\n",
    "        \"estimator__max_iter\": [10000]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dfa30-0e3d-4cf9-bed3-156eec2add05",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c64a627-e8ea-4f21-a667-45921f1529ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes model with consolidate_text and TfidfVectorizer\n",
    "mnb_con_tf_params = {\n",
    "    \"name\": \"mnb_consolidate_tfidf\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"ss\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Multinomial Naive Bayes model with consolidate_text and CountVectorizer\n",
    "mnb_con_count_params = {\n",
    "    \"name\": \"mnb_consolidate_count\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"ss\": False,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Multinomial Naive Bayes model without consolidate_text and TfidfVectorizer\n",
    "mnb_tf_params = {\n",
    "    \"name\": \"mnb_tfidf\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"ss\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Multinomial Naive Bayes model without consolidate_text and CountVectorizer\n",
    "mnb_count_params = {\n",
    "    \"name\": \"mnb_count\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"ss\": False,\n",
    "    \"vec\": CountVectorizer(),\n",
    "    \"estimator\": MultinomialNB(),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, \"english\", new_stop_words],\n",
    "        \"vec__min_df\": [1, 2, 5],\n",
    "        \"vec__max_features\": [None, 5000, 10000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__alpha\": [0, 0.1, 0.5, 1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1389a1e4-2202-45f9-8594-1f64b7bd6dac",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57a373b-6486-41df-88a4-6b39a50bf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifer Model with consolidate_text and TfidfVectorizer\n",
    "rf_params = {\n",
    "    \"name\": \"rf\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"ss\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": RandomForestClassifier(random_state=42),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, new_stop_words],\n",
    "        \"vec__min_df\": [2, 5],\n",
    "        \"vec__max_features\": [None, 5000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__n_estimators\": [50, 150],\n",
    "        \"estimator__max_depth\": [None, 5, 9],\n",
    "        \"estimator__min_samples_leaf\": [3, 7]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f730d44-0c18-4c1a-a048-4925bfbfff38",
   "metadata": {},
   "source": [
    "#### Ada Boost Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e44d7711-8e3c-45fc-a25a-8475573d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada Boost Classifier with consolidate_text and TfidfVectorizer\n",
    "ada_params = {\n",
    "    \"name\": \"ada\",\n",
    "    \"consolidate_text\": True,\n",
    "    \"ss\": False,\n",
    "    \"vec\": TfidfVectorizer(),\n",
    "    \"estimator\": AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state=42),\n",
    "    \"params\": {\n",
    "        \"vec__stop_words\": [None, new_stop_words],\n",
    "        \"vec__min_df\": [2, 5],\n",
    "        \"vec__max_features\": [None, 5000],\n",
    "        \"vec__binary\": [False, True],\n",
    "        \"estimator__n_estimators\": [50, 150, 250],\n",
    "        \"estimator__base_estimator__max_depth\": [None, 5, 9],\n",
    "        \"estimator__base_estimator__min_samples_leaf\": [1, 3, 7]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1ef8c-ff87-487f-b94c-a281722fde4d",
   "metadata": {},
   "source": [
    "#### Support Vector Machine Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d02b7e-4aa3-4055-b04a-055181854219",
   "metadata": {},
   "source": [
    "Because the support vector machine classifier requires scaled data, the text vectorized by TfidfVectorizer needed to be converted from a sparse matrix into a dense matrix before running it through Standard Scaler. The following function addresses that issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "334461c5-5c76-4911-9fbe-b8d6b6e11f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vectorize text data before scaling\n",
    "def vectorize_text(X):\n",
    "    # Create copy of X\n",
    "    df_copy = X.copy()\n",
    "    \n",
    "    # Run consolidate topics function\n",
    "    df_copy = consolidate_topics(df_copy)\n",
    "    \n",
    "    # Instantiate TfidfVectorizer with \n",
    "    vec = TfidfVectorizer(\n",
    "            stop_words = new_stop_words,\n",
    "            max_features = None,\n",
    "            ngram_range = (1,1),\n",
    "            min_df = 2,\n",
    "        )\n",
    "\n",
    "    \n",
    "    df_vec_sparse = vec.fit_transform(df_copy)\n",
    "    df_vec = pd.DataFrame(df_vec_sparse.todense(), columns=vec.get_feature_names())\n",
    "    return df_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17d92f-a926-46d6-8806-5f98646921c8",
   "metadata": {},
   "source": [
    "##### SVM X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff0a1889-8261-47a8-ac69-cae423e771ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Declare X and y for SVM model\n",
    "X_svm = vectorize_text(final_df[\"alltext\"])\n",
    "y_svm = final_df[\"||__target__||\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795c927-b0eb-468a-b59e-69af7a65da6b",
   "metadata": {},
   "source": [
    "##### Train test split for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa7aabf5-75bd-4d8e-80de-884a9b44ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for SVM data\n",
    "X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(X_svm, y_svm, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3f82af0-96f3-4490-a14e-b0c2e40390f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier Parameters for run_gridsearch function\n",
    "\n",
    "svm_params = {\n",
    "    \"name\": \"svm\",\n",
    "    \"consolidate_text\": False,\n",
    "    \"ss\": True,\n",
    "    \"vec\": False,\n",
    "    \"estimator\": SVC(),\n",
    "    \"params\": {\n",
    "        \"estimator__C\": [1, 10],\n",
    "        \"estimator__kernel\": [\"rbf\"],\n",
    "#        \"estimator__degree\": [2, 3],\n",
    "        \"estimator__gamma\": [\"scale\", \"auto\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7187a38-309e-4f5b-afb2-dc631bd153f9",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ec953-a8eb-4170-8f98-6d1ba1e34a0e",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419aaf7-38e0-46eb-a6e2-50498dcaf806",
   "metadata": {},
   "source": [
    "#### Baseline Accuracy Score\n",
    "The baseline accuracy score to compare our model against is shown below by showing the percentage of the observations in our dataset that are classified as class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e62d7b74-f3d5-4739-9fbb-2b9052ba3000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: ||__target__||, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"||__target__||\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008303b9-70be-490b-a90e-7bd460f0c479",
   "metadata": {},
   "source": [
    "Because we balanced the classes during the import and cleaning of our data at the start, we have a baseline accuracy score of 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6599c8-eee2-4720-8d9a-edc004896c68",
   "metadata": {},
   "source": [
    "#### Best Model on Accuracy\n",
    "Of all the models tested through our grid searches, it appears that the logistic regression and Multinomial Naive Bayes classifier models performed the best. Although overfit, they achieved the best accuracy scores on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d377f7e-bb01-4cfb-8163-4c26f222892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scores written to CSV during gridsearches\n",
    "# Filenames of the CSVs correspond with the model and set of parameters used for the gridsearch during which the CSV was written\n",
    "\n",
    "best_scores = []\n",
    "for file in os.listdir(\"../gridsearch_results\"):\n",
    "    if file.split(\"_\")[0] == \"best\":\n",
    "        before_timestamp = file.split(\"-\")[0]\n",
    "        df = pd.read_csv(f'../gridsearch_results/{file}')\n",
    "        df['gridsearch'] = before_timestamp.split(\"_\", 2)[-1]\n",
    "        best_scores.append(df)\n",
    "all_scores = pd.concat(best_scores).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e64406-f05f-4a9d-b22f-1143c6ec5250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gridsearch</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression_consolidate_tfidf</td>\n",
       "      <td>0.909395</td>\n",
       "      <td>0.820244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression_tfidf</td>\n",
       "      <td>0.911576</td>\n",
       "      <td>0.818499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression_count</td>\n",
       "      <td>0.918994</td>\n",
       "      <td>0.811518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression_consolidate_count</td>\n",
       "      <td>0.918557</td>\n",
       "      <td>0.810209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnb_count</td>\n",
       "      <td>0.866492</td>\n",
       "      <td>0.806283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mnb_consolidate_count</td>\n",
       "      <td>0.863583</td>\n",
       "      <td>0.805846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mnb_tfidf</td>\n",
       "      <td>0.880454</td>\n",
       "      <td>0.800175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.895870</td>\n",
       "      <td>0.799738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mnb_consolidate_tfidf</td>\n",
       "      <td>0.879290</td>\n",
       "      <td>0.799738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.745201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.982403</td>\n",
       "      <td>0.696771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               gridsearch     train      test\n",
       "2   logistic_regression_consolidate_tfidf  0.909395  0.820244\n",
       "0               logistic_regression_tfidf  0.911576  0.818499\n",
       "3               logistic_regression_count  0.918994  0.811518\n",
       "5   logistic_regression_consolidate_count  0.918557  0.810209\n",
       "1                               mnb_count  0.866492  0.806283\n",
       "4                   mnb_consolidate_count  0.863583  0.805846\n",
       "7                               mnb_tfidf  0.880454  0.800175\n",
       "8                                      rf  0.895870  0.799738\n",
       "9                   mnb_consolidate_tfidf  0.879290  0.799738\n",
       "10                                    ada  0.999709  0.745201\n",
       "6                                     svm  0.982403  0.696771"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best scores achieved by each gridsearch sorted by scores on the test set\n",
    "all_scores[[\"gridsearch\", \"train\", \"test\"]].sort_values(by=\"test\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12852b-1b18-4d09-9da4-858a1ec0be68",
   "metadata": {},
   "source": [
    "Among these, I believe the Logistic Regression model using our consolidate text function and a TfidfVectorizer is our best model as it achieved the best score on our test set -- 82.02%. I believe this means that this model is the most likely to generalize well and achieve similar accuracy results in classifying new posts from the subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731489f-6f8d-47ac-9237-98d1723cfd8e",
   "metadata": {},
   "source": [
    "#### Other Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f43d0a-9950-489c-baf1-3b5386e3de1e",
   "metadata": {},
   "source": [
    "Our best model also achieves similar scores on other evaluation metrics:\n",
    "\n",
    "1. Weighted avg precision: 82%\n",
    "2. Weighted avg recall: 82%\n",
    "3. F1 score: 82%\n",
    "\n",
    "The code for evaluating our model on these metrics is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa8cca-cd0c-42e9-854a-d6cabba886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipe\n",
    "pipe_best_model = Pipeline([\n",
    "    (\"consolidate\", consolidate_tf),\n",
    "    (\"vec\", TfidfVectorizer()),\n",
    "    (\"estimator\", LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "gs_params_best_model = {\n",
    "    \"vec__stop_words\": [None, new_stop_words],\n",
    "    \"vec__min_df\": [2, 5],\n",
    "    \"vec__max_features\": [None, 5000],\n",
    "    \"vec__binary\": [False, True],\n",
    "    \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "    \"estimator__C\": [0.1,1,10],\n",
    "    \"estimator__max_iter\": [10000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "gs = GridSearchCV(estimator=pipe_best_model, param_grid=gs_params_best_model, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearch\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad4803-9ecb-4fe2-b20e-18422c74d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2a8ea64f-a45f-40ba-9cca-dde21e276095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running consolidate topics\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(final_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fa0f3ac0-5cce-4b87-be28-e58027530b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running consolidate topics\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82      1146\n",
      "           1       0.80      0.85      0.82      1146\n",
      "\n",
      "    accuracy                           0.82      2292\n",
      "   macro avg       0.82      0.82      0.82      2292\n",
      "weighted avg       0.82      0.82      0.82      2292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create predictions on test set\n",
    "predictions_test = final_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, predictions_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1023ff6-26fd-455e-b42a-d974326b95c4",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463989-1595-4459-8883-438c1fbd3faa",
   "metadata": {},
   "source": [
    "To improve upon the accuracy of this model, I would recommend exploring the following next steps:\n",
    "1. Adding more features about the text\n",
    "    - Sentiment analysis on each post\n",
    "    - Counts of the number of words and sentences used in each post\n",
    "2. Exploring other natural language processing strategies to differentiate the subreddits further"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
